{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "odyssey_remake.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehanbchinoy/Math-156-project/blob/main/odyssey_remake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXC6pLGLwS6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:20.439085Z",
          "iopub.status.busy": "2021-11-02T15:27:20.438447Z",
          "iopub.status.idle": "2021-11-02T15:27:22.089310Z",
          "shell.execute_reply": "2021-11-02T15:27:22.088742Z"
        },
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:22.094569Z",
          "iopub.status.busy": "2021-11-02T15:27:22.093270Z",
          "iopub.status.idle": "2021-11-02T15:27:22.300054Z",
          "shell.execute_reply": "2021-11-02T15:27:22.300438Z"
        },
        "id": "pD_55cOxLkAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eed87c9-8e76-422e-ce2c-52daffe15f67"
      },
      "source": [
        "odyssey = tf.keras.utils.get_file('odyssey.txt', 'http://classics.mit.edu/Homer/odyssey.mb.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://classics.mit.edu/Homer/odyssey.mb.txt\n",
            " 417792/Unknown - 0s 0us/step"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "First, look in the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:22.305804Z",
          "iopub.status.busy": "2021-11-02T15:27:22.305175Z",
          "iopub.status.idle": "2021-11-02T15:27:22.309081Z",
          "shell.execute_reply": "2021-11-02T15:27:22.309471Z"
        },
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854804d2-b33e-4f59-ca89-728d54045b28"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(odyssey, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 611300 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:22.313942Z",
          "iopub.status.busy": "2021-11-02T15:27:22.313299Z",
          "iopub.status.idle": "2021-11-02T15:27:22.315709Z",
          "shell.execute_reply": "2021-11-02T15:27:22.316105Z"
        },
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e8a07e-7999-4595-b033-6c4d42564fe5"
      },
      "source": [
        "# Take a look at the first few hundered characters in text\n",
        "print(text[10000:10750]) # starts at 260"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " will\n",
            "not be away much longer; for he is a man of such resource that even\n",
            "though he were in chains of iron he would find some means of getting\n",
            "home again. But tell me, and tell me true, can Ulysses really have\n",
            "such a fine looking fellow for a son? You are indeed wonderfully like\n",
            "him about the head and eyes, for we were close friends before he set\n",
            "sail for Troy where the flower of all the Argives went also. Since\n",
            "that time we have never either of us seen the other.\" \n",
            "\n",
            "\"My mother,\" answered Telemachus, tells me I am son to Ulysses, but\n",
            "it is a wise child that knows his own father. Would that I were son\n",
            "to one who had grown old upon his own estates, for, since you ask\n",
            "me, there is no more ill-starred man under heaven than he who they\n",
            "tell me i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:22.334707Z",
          "iopub.status.busy": "2021-11-02T15:27:22.333933Z",
          "iopub.status.idle": "2021-11-02T15:27:22.336358Z",
          "shell.execute_reply": "2021-11-02T15:27:22.336756Z"
        },
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39115be-8176-4ef3-f382-befbfc79be49"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.008964Z",
          "iopub.status.busy": "2021-11-02T15:27:24.008424Z",
          "iopub.status.idle": "2021-11-02T15:27:24.019830Z",
          "shell.execute_reply": "2021-11-02T15:27:24.019329Z"
        },
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.033230Z",
          "iopub.status.busy": "2021-11-02T15:27:24.032310Z",
          "iopub.status.idle": "2021-11-02T15:27:24.038956Z",
          "shell.execute_reply": "2021-11-02T15:27:24.038487Z"
        },
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.067541Z",
          "iopub.status.busy": "2021-11-02T15:27:24.066635Z",
          "iopub.status.idle": "2021-11-02T15:27:24.068490Z",
          "shell.execute_reply": "2021-11-02T15:27:24.068840Z"
        },
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.076205Z",
          "iopub.status.busy": "2021-11-02T15:27:24.075417Z",
          "iopub.status.idle": "2021-11-02T15:27:24.475303Z",
          "shell.execute_reply": "2021-11-02T15:27:24.474777Z"
        },
        "id": "UopbsKi88tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed6b0c3-4f31-4619-d3ba-37b6883b3ecd"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(611300,), dtype=int64, numpy=array([36, 66, 63, ..., 27, 10,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.481008Z",
          "iopub.status.busy": "2021-11-02T15:27:24.480019Z",
          "iopub.status.idle": "2021-11-02T15:27:24.482800Z",
          "shell.execute_reply": "2021-11-02T15:27:24.482316Z"
        },
        "id": "qmxrYDCTy-eL"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.488049Z",
          "iopub.status.busy": "2021-11-02T15:27:24.487126Z",
          "iopub.status.idle": "2021-11-02T15:27:24.505087Z",
          "shell.execute_reply": "2021-11-02T15:27:24.504541Z"
        },
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2b5270-615e-4373-bbd4-02241e3e3009"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P\n",
            "r\n",
            "o\n",
            "v\n",
            "i\n",
            "d\n",
            "e\n",
            "d\n",
            " \n",
            "b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.509104Z",
          "iopub.status.busy": "2021-11-02T15:27:24.508476Z",
          "iopub.status.idle": "2021-11-02T15:27:24.510839Z",
          "shell.execute_reply": "2021-11-02T15:27:24.510328Z"
        },
        "id": "C-G2oaTxy6km"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.515883Z",
          "iopub.status.busy": "2021-11-02T15:27:24.515230Z",
          "iopub.status.idle": "2021-11-02T15:27:24.525779Z",
          "shell.execute_reply": "2021-11-02T15:27:24.525284Z"
        },
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f98a0d-85f4-4e2b-8225-3d12bd21e6ca"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'P' b'r' b'o' b'v' b'i' b'd' b'e' b'd' b' ' b'b' b'y' b' ' b'T' b'h'\n",
            " b'e' b' ' b'I' b'n' b't' b'e' b'r' b'n' b'e' b't' b' ' b'C' b'l' b'a'\n",
            " b's' b's' b'i' b'c' b's' b' ' b'A' b'r' b'c' b'h' b'i' b'v' b'e' b'.'\n",
            " b'\\n' b'S' b'e' b'e' b' ' b'b' b'o' b't' b't' b'o' b'm' b' ' b'f' b'o'\n",
            " b'r' b' ' b'c' b'o' b'p' b'y' b'r' b'i' b'g' b'h' b't' b'.' b' ' b'A'\n",
            " b'v' b'a' b'i' b'l' b'a' b'b' b'l' b'e' b' ' b'o' b'n' b'l' b'i' b'n'\n",
            " b'e' b' ' b'a' b't' b'\\n' b' ' b' ' b' ' b' ' b'h' b't' b't' b'p' b':'\n",
            " b'/' b'/' b'c'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "It's easier to see what this is doing if you join the tokens back into strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.530583Z",
          "iopub.status.busy": "2021-11-02T15:27:24.529970Z",
          "iopub.status.idle": "2021-11-02T15:27:24.540839Z",
          "shell.execute_reply": "2021-11-02T15:27:24.541244Z"
        },
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043c70f8-4891-418b-ae08-f48d905e732f"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Provided by The Internet Classics Archive.\\nSee bottom for copyright. Available online at\\n    http://c'\n",
            "b'lassics.mit.edu//Homer/odyssey.html\\n\\nThe Odyssey\\nBy Homer\\n\\n\\nTranslated by Samuel Butler\\n\\n------------'\n",
            "b'----------------------------------------------------------\\n\\nBOOK I\\n\\nTell me, O muse, of that ingeniou'\n",
            "b's hero who travelled far and wide\\nafter he had sacked the famous town of Troy. Many cities did he vis'\n",
            "b'it,\\nand many were the nations with whose manners and customs he was acquainted;\\nmoreover he suffered '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "For training you'll need a dataset of `(input, label)` pairs. Where `input` and \n",
        "`label` are sequences. At each time step the input is the current character and the label is the next character. \n",
        "\n",
        "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.545858Z",
          "iopub.status.busy": "2021-11-02T15:27:24.545232Z",
          "iopub.status.idle": "2021-11-02T15:27:24.547119Z",
          "shell.execute_reply": "2021-11-02T15:27:24.547538Z"
        },
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.552647Z",
          "iopub.status.busy": "2021-11-02T15:27:24.551983Z",
          "iopub.status.idle": "2021-11-02T15:27:24.554282Z",
          "shell.execute_reply": "2021-11-02T15:27:24.554707Z"
        },
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb00f994-68bc-46e3-ab4d-4c98865b23b3"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.576996Z",
          "iopub.status.busy": "2021-11-02T15:27:24.559970Z",
          "iopub.status.idle": "2021-11-02T15:27:24.607232Z",
          "shell.execute_reply": "2021-11-02T15:27:24.606589Z"
        },
        "id": "B9iKPXkw5xwa"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.612341Z",
          "iopub.status.busy": "2021-11-02T15:27:24.611662Z",
          "iopub.status.idle": "2021-11-02T15:27:24.633808Z",
          "shell.execute_reply": "2021-11-02T15:27:24.633287Z"
        },
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fb6c66-618f-4371-989d-d1fd10985760"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'Provided by The Internet Classics Archive.\\nSee bottom for copyright. Available online at\\n    http://'\n",
            "Target: b'rovided by The Internet Classics Archive.\\nSee bottom for copyright. Available online at\\n    http://c'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training batches\n",
        "\n",
        "You used `tf.data` to split the text into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.639517Z",
          "iopub.status.busy": "2021-11-02T15:27:24.638851Z",
          "iopub.status.idle": "2021-11-02T15:27:24.645399Z",
          "shell.execute_reply": "2021-11-02T15:27:24.644907Z"
        },
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fde02a-4908-4b09-833d-7a220131fcb0"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "This model has three layers:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
        "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
        "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.650041Z",
          "iopub.status.busy": "2021-11-02T15:27:24.649417Z",
          "iopub.status.idle": "2021-11-02T15:27:24.651226Z",
          "shell.execute_reply": "2021-11-02T15:27:24.651638Z"
        },
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.658863Z",
          "iopub.status.busy": "2021-11-02T15:27:24.658165Z",
          "iopub.status.idle": "2021-11-02T15:27:24.660531Z",
          "shell.execute_reply": "2021-11-02T15:27:24.659981Z"
        },
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.665152Z",
          "iopub.status.busy": "2021-11-02T15:27:24.664518Z",
          "iopub.status.idle": "2021-11-02T15:27:24.678631Z",
          "shell.execute_reply": "2021-11-02T15:27:24.678096Z"
        },
        "id": "IX58Xj9z47Aw"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Try the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:24.684237Z",
          "iopub.status.busy": "2021-11-02T15:27:24.683548Z",
          "iopub.status.idle": "2021-11-02T15:27:29.121970Z",
          "shell.execute_reply": "2021-11-02T15:27:29.121383Z"
        },
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2535504a-b2b1-421e-ccab-07a85f438ded"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 75) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.129024Z",
          "iopub.status.busy": "2021-11-02T15:27:29.128397Z",
          "iopub.status.idle": "2021-11-02T15:27:29.131378Z",
          "shell.execute_reply": "2021-11-02T15:27:29.131756Z"
        },
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbc6e95-7e91-4da8-d31a-8c770339140a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  19200     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  76875     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,034,379\n",
            "Trainable params: 4,034,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Attach an optimizer, and a loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.159670Z",
          "iopub.status.busy": "2021-11-02T15:27:29.158965Z",
          "iopub.status.idle": "2021-11-02T15:27:29.161294Z",
          "shell.execute_reply": "2021-11-02T15:27:29.160823Z"
        },
        "id": "ZOeWdgxNFDXq"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.165766Z",
          "iopub.status.busy": "2021-11-02T15:27:29.165174Z",
          "iopub.status.idle": "2021-11-02T15:27:29.171904Z",
          "shell.execute_reply": "2021-11-02T15:27:29.172271Z"
        },
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9ccc06-4e48-4405-e34d-4eea57ea5142"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 75)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.3162036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.176806Z",
          "iopub.status.busy": "2021-11-02T15:27:29.176042Z",
          "iopub.status.idle": "2021-11-02T15:27:29.179765Z",
          "shell.execute_reply": "2021-11-02T15:27:29.180141Z"
        },
        "id": "MAJfS5YoFiHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64ee40b-ab2a-4577-a86a-4f05aaa26125"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.90372"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.187498Z",
          "iopub.status.busy": "2021-11-02T15:27:29.186911Z",
          "iopub.status.idle": "2021-11-02T15:27:29.192407Z",
          "shell.execute_reply": "2021-11-02T15:27:29.191945Z"
        },
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.197040Z",
          "iopub.status.busy": "2021-11-02T15:27:29.196404Z",
          "iopub.status.idle": "2021-11-02T15:27:29.198784Z",
          "shell.execute_reply": "2021-11-02T15:27:29.198347Z"
        },
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.202743Z",
          "iopub.status.busy": "2021-11-02T15:27:29.202094Z",
          "iopub.status.idle": "2021-11-02T15:27:29.204196Z",
          "shell.execute_reply": "2021-11-02T15:27:29.204596Z"
        },
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:27:29.208741Z",
          "iopub.status.busy": "2021-11-02T15:27:29.208178Z",
          "iopub.status.idle": "2021-11-02T15:29:16.409766Z",
          "shell.execute_reply": "2021-11-02T15:29:16.409126Z"
        },
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db91c72c-f44f-4cde-c19c-290bab505b1b"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 20s 186ms/step - loss: 2.8621\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 18s 186ms/step - loss: 2.1454\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 18s 187ms/step - loss: 1.8908\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.6878\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.5374\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.4290\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.3454\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.2788\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.2233\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.1715\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.1235\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.0770\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 1.0301\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.9804\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.9306\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.8771\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.8210\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 18s 183ms/step - loss: 0.7628\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.7023\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 18s 184ms/step - loss: 0.6422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:29:16.420217Z",
          "iopub.status.busy": "2021-11-02T15:29:16.419249Z",
          "iopub.status.idle": "2021-11-02T15:29:16.421625Z",
          "shell.execute_reply": "2021-11-02T15:29:16.421181Z"
        },
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:29:16.427012Z",
          "iopub.status.busy": "2021-11-02T15:29:16.426081Z",
          "iopub.status.idle": "2021-11-02T15:29:16.434123Z",
          "shell.execute_reply": "2021-11-02T15:29:16.434480Z"
        },
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:29:16.441547Z",
          "iopub.status.busy": "2021-11-02T15:29:16.440495Z",
          "iopub.status.idle": "2021-11-02T15:29:18.760200Z",
          "shell.execute_reply": "2021-11-02T15:29:18.759014Z"
        },
        "id": "ST7PSyk9t1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e28f75-d975-4cce-f596-196ff0325828"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Telemachus'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Telemachus, \"Stranger,\" said Ulysses,\n",
            "\"dy quiver there is nothing better of arrows. Everything as she took his head and bronze\n",
            "with his old day.\" \n",
            "\n",
            "Minerva answered, \"Stranger, do you or night well, and the sure Archare\n",
            "begins whoever him by force, and saying in his crew while death\n",
            "will happen as ever you may, your people were\n",
            "all sorts of going to put his hands over me against I inswered, 'Sir, with the arrows on ours, for some of your\n",
            "wife and chew brives nord that some of Neptune had had heant of\n",
            "wien. When they raised a cred town and wealth, for we had had their hosts such as\n",
            "go to the house there nwill of you to do, from what nurse that she went about getting it,\n",
            "littening to be well disposed towards the time. My noble savoder\n",
            "Eubaechan about the young home will not retine stones, and I had had enough\n",
            "to kill him, instead of a handsome\n",
            "resounded with places for for Pylos never dinner ready, lunger on\n",
            "it and she stowed on ining himself in his own eyes, and every\n",
            "man called me, on the first  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.907065153121948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:29:18.774687Z",
          "iopub.status.busy": "2021-11-02T15:29:18.773101Z",
          "iopub.status.idle": "2021-11-02T15:29:21.035633Z",
          "shell.execute_reply": "2021-11-02T15:29:21.035156Z"
        },
        "id": "ZkLu7Y8UCMT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d50bbf5-840e-410c-fd2e-d224854c197e"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Odysseus:', 'Odysseus:', 'Odysseus:', 'Odysseus:', 'Odysseus:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Odysseus: They say you are the sacrefts\\nyou will be not marriage in the lot and unborning and\\nrauged it. At the hand of heaven was and given me all blood they went to\\nthe linen and divided it ready, Telemachus is word on and on with the ever-living\\nof king Prelapentane;\\nbut when Jove bring them does. \\n\\n\"Even so, then, when I saw him I to return. He snatched up three upon men and smoke Minoss valiant who about my hands\\nin Laertes and the sails, took Telemachus to go back and smote the doorway\\nof the spoil and wore themselves to make him in the likeness of a wound.\\nStick they did not desire. Suppose I must come with my ships against your own people, who are shaft killed him.\" \\n\\nThey daughter of Overing-pook were golden and attented them. The Nestor was away\\nalded, and every man had entered their mouths trusting with which they sun he touch them as\\nthough he were us old and earth. We must not be\\nhis feasting to your own cosseate. For the storm wrong the Whole headls know more and Diomar, and the v'\n",
            " b'Odysseus: When he grows upon\\nthe lid on to she set out with easy- but her up, and had drung\\nout their portions on; Whereon the maids all brooding his eyes as hardly attended me, but Jove\\nshall rol be before here, for he rejeided prayer that\\nyou have said is well dressed, while they have killed it will. May\\nyour dear father woo were fifth yest according the vidy and\\nwent waiting to the Theban prophet Teires.\\nHere we sang for the wind and waves against\\nthe wine that had been given to sleep. The land of voatust among my heavy\\nvalue in its tale, or fly they all came also-her, and I have told\\nus what was than held. Go there not fly after his breashand\\nand prepty out and know what had happened, for he had assembled\\nand sprinkling at every, Ulysses cast looking upon the whole are\\nof braze. Then they started at once and took his sandals on the cross pall.\\'\\n\\n\"The Denis way in which you can set you out, took about still and\\nfortune; when he went with the sports she shows what you have lefty. Shilt there '\n",
            " b'Odysseus: you must ow me, and had been\\nindeed cauldrvales lay in his old age, you may hear the way in\\nwhich the sea greater Argicans over as they made doors of virtue\\nship; it was sorrowfully the daughter of Aca; whom Nestor, sons of his father;\\nhe was and his crew were closed with cappering soon\\ndancing; he must he not tell any counsels on your loom, or shin it on my ratter looks of\\nwith gorefficiny. Find me as soon as he had got in and know of the\\nCyclopes. It is the river I partied, for six days even you can say\\nwhat I had said? What did Alcinous; Jove has\\nnever get it best, saying: \\n\\n\"What are you know one remains at the house, dear in my ship with\\nMenelaus\\' and brooded. Then they have boing not and\\nkeep quiet, and a bard who will\\ngive him the stranger and stood by oit, but her father went back to the ships, tull some one\\nof my recear and gives eary bed with Jove. This began to wait first\\nontered or the best to all this he went away in the world, neither god\\nnor man with an eagle-jealter, a'\n",
            " b'Odysseus: Himself, he were a long\\nway must not know what to think) as this man by man, and were your first\\none or other instinc: he will bring on\\nthe slut of a murderers. There he crept from the rudder good\\nand mind. Then Ulysses continual devines from the bottom of the door, and he had already badly\\ntill it had been to get away throwing dismay one and all of them\\nlieat upon his shirt and cloak of two dirtHess of what nine and\\ndresched. as yourself, can you not go to the house\\nhigh up with everalasicual. Now, however, I had got apide when a man of stringing himself and\\nhove to do if he goes at last, and she had done so with a silver cloak\\nwithout deversate among them many voyage to wark him.\" \\n\\nAnd his arrow through them, but are a moment and brilding race we pair over yond of this people about my husband, for we had heard it from his lying\\nstill past. \"Moreovery the Phaeacians\\nwere surpaising to your house to go to bed either\\nNereus to do as you have said. But Antiphatais\\nlast his sable fast f'\n",
            " b'Odysseus: \\n\\nSo Veen served, and heaven has also give him one fat in the world was not going to speak,\\nand his fruitless resicfedle bank, for hervans took their places and smote the grey own handed am near him.\\n\\nThen Antinous scolded himself, and they were in a tire and awritus were well grown,\\nand threw it, and paying coared with myself, for he was\\nalready do you suppoct you. I do not like to went right through the\\nmiddle of the city if ho\\npiteously.\" \\n\\nUlysses was departed not by which I saw them, some\\nof you who kyes might have to death with a swive herd\\nwith Minerva; it has always good tool out of pretty, and see how I saw Ulysses never broke\\nhis orders and his bedless of my house, which was a stranger, and\\nthus was going on, by gilding, nor can detting blied one after her hand,\\nand made a marined om bows and spitter thack even struck me as\\nthough you were going, and more upon the ghosts stood before\\nAceilanus; she said to have settled them little fast, and then caught him by the hide, came\\n'], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.5761048793792725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-02T15:29:21.040688Z",
          "iopub.status.busy": "2021-11-02T15:29:21.040105Z",
          "iopub.status.idle": "2021-11-02T15:29:27.534522Z",
          "shell.execute_reply": "2021-11-02T15:29:27.534989Z"
        },
        "id": "3Grk32H_CzsC",
        "outputId": "87df51d8-49e1-452b-c603-77091be80556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f76b7b68ed0>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T2IQYLS2yrj",
        "outputId": "6b704cca-cf43-4d55-d278-858f0fc7f9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Colab Notebooks/checkpoint_epoch20')"
      ],
      "metadata": {
        "id": "OcfvlrBG3gxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/odyssey_saved_model_epoch20')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eyL_fs23t85",
        "outputId": "797f801d-b8d0-415b-97f5-0c8aa5959cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/odyssey_saved_model_epoch20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/odyssey_saved_model_epoch20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f76b8f14450> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    }
  ]
}