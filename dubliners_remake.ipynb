{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dubliners_remake.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehanbchinoy/Math-156-project/blob/main/dubliners_remake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i3v2jf9YcpF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import base64\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NFP7eU_glCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c434c7af-5309-4e1f-ff3f-862018234a13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN6_apUZYcpN"
      },
      "source": [
        "#read the txt file to str\n",
        "master = \"https://raw.githubusercontent.com/rehanbchinoy/Math-156-project/main/dubliners_james_joyce.txt\"\n",
        "req = requests.get(master)\n",
        "dubliners = req.text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-pvavTZZO0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8719a96-c0fe-41b3-d540-42eeba1fa1fb"
      },
      "source": [
        "len(dubliners)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "377403"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gsSW7IYcpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccacb8a-4094-4f61-fcf9-2d35413916d9"
      },
      "source": [
        "#unique characters in the file\n",
        "vocab = sorted(set(dubliners))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0f9GH9LYcpT"
      },
      "source": [
        "## Process the Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdR5PlV7YcpW"
      },
      "source": [
        "### Vectorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOilAdPLYcpW"
      },
      "source": [
        "#function that converts character tokens to numeric ids\n",
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQgNRjAYcpY"
      },
      "source": [
        "#function that converts numeric ids to character tokens\n",
        "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTVgSQ3PYcpZ"
      },
      "source": [
        "#function that combines character tokens back to strings\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ENNjjV2Ycpa"
      },
      "source": [
        "### Creating training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIrPa7cOYcpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835cf45c-e40f-4ba2-dc39-b625aa46149c"
      },
      "source": [
        "#convert dubliners from strings to numeric vector\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(dubliners, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(377403,), dtype=int64, numpy=array([39, 27, 24, ..., 47, 50, 10])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFUYl9oYcpc"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmbgr6zoYcpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87736ad1-ee6a-4aee-efe6-c83e572db9f1"
      },
      "source": [
        "#verify the ids dataset is correct\n",
        "for ids in ids_dataset.take(100):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "H\n",
            "E\n",
            " \n",
            "S\n",
            "I\n",
            "S\n",
            "T\n",
            "E\n",
            "R\n",
            "S\n",
            "\r\n",
            "\n",
            "\n",
            "\r\n",
            "\n",
            "\n",
            "\r\n",
            "\n",
            "\n",
            "T\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "n\n",
            "o\n",
            " \n",
            "h\n",
            "o\n",
            "p\n",
            "e\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "m\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            ":\n",
            " \n",
            "i\n",
            "t\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "r\n",
            "d\n",
            " \n",
            "s\n",
            "t\n",
            "r\n",
            "o\n",
            "k\n",
            "e\n",
            ".\n",
            " \n",
            "N\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "\r\n",
            "\n",
            "\n",
            "a\n",
            "f\n",
            "t\n",
            "e\n",
            "r\n",
            " \n",
            "n\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "I\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2eM_YBfYcpf"
      },
      "source": [
        "#split the text into sequences with length 100\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(dubliners)//(seq_length+1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYtWdNiYcph"
      },
      "source": [
        "#create the sequences based on sequences with length 101\n",
        "#(it's 101 bc we need to split it into training and target sequences)\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuYNxm21Ycph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959ced2c-31fc-4307-f2fd-613c994f859a"
      },
      "source": [
        "#verify the sequences are created correctly\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'T' b'H' b'E' b' ' b'S' b'I' b'S' b'T' b'E' b'R' b'S' b'\\r' b'\\n' b'\\r'\n",
            " b'\\n' b'\\r' b'\\n' b'T' b'h' b'e' b'r' b'e' b' ' b'w' b'a' b's' b' ' b'n'\n",
            " b'o' b' ' b'h' b'o' b'p' b'e' b' ' b'f' b'o' b'r' b' ' b'h' b'i' b'm'\n",
            " b' ' b't' b'h' b'i' b's' b' ' b't' b'i' b'm' b'e' b':' b' ' b'i' b't'\n",
            " b' ' b'w' b'a' b's' b' ' b't' b'h' b'e' b' ' b't' b'h' b'i' b'r' b'd'\n",
            " b' ' b's' b't' b'r' b'o' b'k' b'e' b'.' b' ' b'N' b'i' b'g' b'h' b't'\n",
            " b'\\r' b'\\n' b'a' b'f' b't' b'e' b'r' b' ' b'n' b'i' b'g' b'h' b't' b' '\n",
            " b'I' b' ' b'h'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpzHsJWLYcpi"
      },
      "source": [
        "#generate the target sequence for each sequence\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOt0l5gbYcpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba3fea5-3d7e-4ab9-8fe4-f57ea7b5d80c"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "dataset"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsocR7AKYcpk"
      },
      "source": [
        "### Create Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azDocwGlYcpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc35b9ac-649a-4926-8ba3-e95d8f61ef20"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJIrNKWAYcpl"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-c_Gyt7Ycpm"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG4Iu-L_Ycpn"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        " \n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc7mIDZxYcpo"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ncgwtuMYcpp"
      },
      "source": [
        "## Try The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D7dES8Ha4DP"
      },
      "source": [
        "Run the model to see if the output is as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkU2FKgRYcpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878e751f-b7cb-4677-9db2-8e694d4c97fe"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-I7jtTccTAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3c09c9-03c4-411e-89eb-af39810e7254"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  21248     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  85075     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,044,627\n",
            "Trainable params: 4,044,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIvjd5wIcWTZ"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlXS0mQScYDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbdbc45-3bc3-4f1a-d386-d083dcc7ea5f"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'ntaining a subject in the\\r\\nthird person and a predicate in the past tense. He never gave alms to\\r\\nbe'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'1MLTAHxEed&TZw8VM-tF951jUnX\\xe2\\x80\\x9cf.d\\roGc1fkH&FlBMMado\\xc3\\xa7NHsW.t\\xe2\\x80\\x9c.bFJ__t\\xc5\\x93IcE\\xc3\\xa6sX\\xe2\\x80\\x94\\rW[UNK]WWAFoi1WdgOeL\\xc3\\xa8\\xe2\\x80\\x94rHDDB\\nclpeW'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt8Gn-Nicdc6"
      },
      "source": [
        "## Train The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-DhtPJpcntV"
      },
      "source": [
        "### Add optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPAsfw_4cl-V"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OETdXQo4cs7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19c6cd4-7930-41a8-a4db-edba190ba8d5"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.4218397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cNBocToc4ML"
      },
      "source": [
        "Check to make sure the loss is roughly the same as the vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6U2zfScuiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a2f5c4-a973-41ef-dabb-dc6e92aea869"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.2493"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pooNw_7GcyFM"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP9HXRw2eabi"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK2tK73qeTNC"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks'\n",
        "# Name of the checkpoint files\n",
        "#checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_dir,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eir0nBPdexh-"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZQxpZTSev23"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh1camR9e-d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64681098-f5fa-440b-abbd-6bbc073acc54"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "58/58 [==============================] - 11s 143ms/step - loss: 3.3540\n",
            "Epoch 2/20\n",
            "58/58 [==============================] - 9s 140ms/step - loss: 2.4043\n",
            "Epoch 3/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 2.2208\n",
            "Epoch 4/20\n",
            "58/58 [==============================] - 9s 140ms/step - loss: 2.0803\n",
            "Epoch 5/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.9454\n",
            "Epoch 6/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.8225\n",
            "Epoch 7/20\n",
            "58/58 [==============================] - 9s 141ms/step - loss: 1.7081\n",
            "Epoch 8/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.6070\n",
            "Epoch 9/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.5213\n",
            "Epoch 10/20\n",
            "58/58 [==============================] - 9s 143ms/step - loss: 1.4505\n",
            "Epoch 11/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.3876\n",
            "Epoch 12/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.3278\n",
            "Epoch 13/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.2756\n",
            "Epoch 14/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.2220\n",
            "Epoch 15/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.1729\n",
            "Epoch 16/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.1233\n",
            "Epoch 17/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.0709\n",
            "Epoch 18/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 1.0170\n",
            "Epoch 19/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 0.9596\n",
            "Epoch 20/20\n",
            "58/58 [==============================] - 9s 142ms/step - loss: 0.9016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsG90V5ayWNl"
      },
      "source": [
        "#model.save_weights('/content/drive/MyDrive/Colab Notebooks/checkpoint_epoch20')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEuxCLwFzsz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7cc573-4a7c-4a0f-893c-9bcb3d3edfd4"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/dubliners_saved_model_epoch20')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/dubliners_saved_model_epoch20/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/dubliners_saved_model_epoch20/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f02900c0850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URrnEhSQnMr8"
      },
      "source": [
        "## Generate Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPFDHclLnM9T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhodc1uSim_0"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJn4NnmrnSgW"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMKebVzdnVPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5597de0-e1a1-4f3a-aa38-1ccee867b365"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Duke'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duke pulling knee. To express through the respectfull of\r\n",
            "Sinceralt from Bridge they used to puff your took let his nose in by\r\n",
            "downstairs upoticular whose latesting for their little old father involdst by her\r\n",
            "hat into easisty. Little Browne, both began to money on to it in to\r\n",
            "Dellanch world. Saturday taking them the Pewspaper hold\r\n",
            "hoce, it she do so?” asked Gabriel, “I see you down and So,”\r\n",
            "\r\n",
            "Mr Browne took handing sofficely and saiding out of the night in\r\n",
            "Stitizal attention the day a distro had been roof down at his plotes and entored the closely\r\n",
            "in the age of his own lival pings! Miss Healy said selled upon his\r\n",
            "moustache. He was a plain home my sons as she did not question that his\r\n",
            "mind. Gro barrged him in her eyes and looked as if he was in go to plundave ;iphatius. O’H\r\n",
            "assumat at herr she got one of the\r\n",
            "other two men who were to sing that it wasn’t a joy to that was one night where once cake\r\n",
            "their enesn by their turs and loose from the great pleasane in his creed,\r\n",
            "stood to \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.554058313369751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hymt79eltFlW"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "https://arxiv.org/pdf/1308.0850.pdf\n"
      ],
      "metadata": {
        "id": "2lVaNsGDyVYN"
      }
    }
  ]
}